{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"emsemble.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNbyItUwzaW5m4ih6ZxzRlz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kZBnUXIR9oVs","executionInfo":{"status":"ok","timestamp":1638490453952,"user_tz":300,"elapsed":50854,"user":{"displayName":"胡明哲","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14614187422162607500"}},"outputId":"ad45ec94-590d-4027-ca42-5f20229d0adb"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive/\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lWupr4HpAf0P","executionInfo":{"status":"ok","timestamp":1638490546344,"user_tz":300,"elapsed":321,"user":{"displayName":"胡明哲","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14614187422162607500"}},"outputId":"2b3da354-ae67-4399-ca39-d814e82d3af8"},"source":["import sys\n","import os\n","path = '/content/drive/My Drive'\n","sys.path.append(path)\n","os.chdir(path)\n","%cd BDA 21"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/BDA 21\n"]}]},{"cell_type":"markdown","metadata":{"id":"ArrAbeDR40Fz"},"source":["load_data"]},{"cell_type":"code","metadata":{"id":"9i7ew6Jq41xv"},"source":["import pandas as pd\n","\n","\n","def load_dataset(path):\n","    data = pd.read_csv(path)\n","    y = data.loc[:, \"label\"].values.astype(int)\n","    X = data.iloc[:, 3:9].values\n","    return X, y"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r1kXoDWX9zCZ"},"source":["resample"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rf1xIFhoAeS6","executionInfo":{"status":"ok","timestamp":1638490555328,"user_tz":300,"elapsed":5721,"user":{"displayName":"胡明哲","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14614187422162607500"}},"outputId":"b8c09874-8dfc-4d3c-e82f-c159e89c41de"},"source":["!pip install pytorch-tabnet\n","!pip install imblearn"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-tabnet\n","  Downloading pytorch_tabnet-3.1.1-py3-none-any.whl (39 kB)\n","Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.10.0+cu111)\n","Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.4.1)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.19.5)\n","Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.0.1)\n","Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (4.62.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.0.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (3.10.0.2)\n","Installing collected packages: pytorch-tabnet\n","Successfully installed pytorch-tabnet-3.1.1\n","Requirement already satisfied: imblearn in /usr/local/lib/python3.7/dist-packages (0.0)\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (from imblearn) (0.8.1)\n","Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.0.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.1.0)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.4.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.19.5)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (3.0.0)\n"]}]},{"cell_type":"code","metadata":{"id":"wuUzywCJAec1"},"source":["from imblearn.over_sampling import * \n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import normalize\n","import numpy as np\n","\n","\n","def resampling(X, y):\n","    kmeans_sm = KMeansSMOTE(random_state=42, cluster_balance_threshold=0.05)\n","    X_res, y_res = kmeans_sm.fit_resample(X, y)\n","    # svm_sm = SVMSMOTE(random_state=42)\n","    # X_res2, y_res2 = svm_sm.fit_resample(X, y)\n","    # return np.vstack((X_res, X_res2)), np.hstack((y_res, y_res2))\n","    return X_res, y_res\n","\n","\n","def data_preprocess(X):\n","    return normalize(X, axis=0)\n","\n","\n","def cross_validation(X_train, Y_train):\n","    five_fold_data = list()\n","    kf = KFold(n_splits=5, random_state=42, shuffle=True)\n","    for train_index, eval_index in kf.split(X_train):\n","        x_train, x_eval = X_train[train_index], X_train[eval_index]\n","        y_train, y_eval = Y_train[train_index], Y_train[eval_index]\n","        five_fold_data.append([(x_train, y_train), (x_eval, y_eval)])\n","    return five_fold_data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"145k7oNa5RMo"},"source":["use tabnet with pretraining"]},{"cell_type":"code","metadata":{"id":"TzSee_QP5Qb5"},"source":["from pytorch_tabnet.tab_model import TabNetClassifier\n","from pytorch_tabnet.pretraining import TabNetPretrainer\n","import torch\n","import torch.nn as nn\n","from sklearn.metrics import accuracy_score, roc_auc_score, recall_score\n","\n","\n","def train(five_fold_data, X_pretrain):\n","    unsupervised_model = TabNetPretrainer(\n","    optimizer_fn=torch.optim.Adam,\n","    optimizer_params=dict(lr=2e-2),\n","    mask_type='entmax' # \"sparsemax\"\n","    )\n","\n","    unsupervised_model.fit(\n","        X_train=X_pretrain,\n","        eval_set=[X_pretrain],\n","        pretraining_ratio=0.8,\n","    )\n","    clf = TabNetClassifier(\n","        optimizer_fn=torch.optim.Adam,\n","        optimizer_params=dict(lr=2e-2),\n","        scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n","                        \"gamma\":0.9},\n","        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n","        mask_type='entmax' # This will be overwritten if using pretrain model\n","    )\n","\n","    model_sets = list()\n","    # indices = np.random.choice(5, size=3, replace=False)\n","    for i, [(x_train, y_train), (x_eval, y_eval)] in enumerate(five_fold_data):\n","        clf.fit(\n","            X_train=x_train, y_train=y_train, \n","            eval_set=[(x_train, y_train), (x_eval, y_eval)],\n","            eval_name=['train', 'valid'],\n","            eval_metric=['auc', 'accuracy'],\n","            from_unsupervised=unsupervised_model\n","    )\n","        # if i in indices:\n","        model_sets.append(clf)\n","    return model_sets\n","\n","\n","def tabnet_test(model_sets, X_test, y_test):\n","    results = np.zeros((5, len(X_test)))\n","    for i, model in enumerate(model_sets):\n","        preds = model.predict_proba(X_test)\n","        results[i] = preds[:, 1]\n","    score = results.mean(axis=-2)\n","    pred = (score>0.85).astype(int)\n","    recall = recall_score(y_true=y_test, y_pred=pred)\n","    return accuracy_score(y_pred=pred, y_true=y_test), roc_auc_score(y_test, score), recall, pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nG0eKmMqohSd"},"source":["from sklearn.ensemble import AdaBoostClassifier\n","\n","\n","def tree_decider(X_train, y_train, X_test, y_test):\n","    clf = AdaBoostClassifier(n_estimators=100, random_state=0)  \n","    clf.fit(X_train, y_train)\n","    pred = clf.predict(X_test)\n","    prob = clf.predict_proba(X_test)[:, 1]\n","    acc = accuracy_score(y_pred=pred, y_true=y_test)\n","    auc = roc_auc_score(y_test, prob, average=\"samples\")\n","    recall = recall_score(y_test, pred)\n","    return acc, auc, recall, pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dpMwCJVWs1XV"},"source":["from sklearn.linear_model import LogisticRegressionCV\n","\n","\n","def linear_model(train_X, train_y, test_X, test_y):\n","    clf = LogisticRegressionCV(cv=5, penalty=\"l2\", random_state=42, multi_class=\"ovr\", solver=\"liblinear\")\n","    clf.fit(train_X, train_y)\n","    pred = clf.predict(test_X)\n","    prob = clf.predict_proba(test_X)[:, 1]\n","    acc = accuracy_score(y_pred=pred, y_true=test_y)\n","    auc = roc_auc_score(test_y, prob, average=\"samples\")\n","    recall = recall_score(test_y, pred)\n","    return acc, auc, recall, pred"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aCGuMdnvqPq1"},"source":["ensemble"]},{"cell_type":"code","metadata":{"id":"dQwcB7TYqOzD"},"source":["def ensemble(results_tabnet, results_linear, results_tree, y_test):\n","    final_results = np.empty((len(results_tabnet)))\n","    for i in range(len(results_tabnet)):\n","        final_results[i] = np.random.choice([results_tabnet[i], results_linear[i], results_tree[i]])\n","    acc = accuracy_score(y_pred=final_results, y_true=y_test)\n","    recall = recall_score(y_test, final_results)\n","    return acc, recall"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bvSAu7WDt0Kc"},"source":["def full_train():\n","    train_X, train_y = load_dataset(\"player_stats_2019_2020.csv\")\n","    test_X, test_y = load_dataset(\"player_stats_2020_2021.csv\")\n","    train_X_norm = data_preprocess(train_X)\n","    test_X_norm = data_preprocess(test_X)\n","    acc, auc, recall, results_linear = linear_model(train_X_norm, train_y, test_X_norm, test_y)\n","    print(\"linear model: acc is {:.5f}, auc is {:.5f} and recall is {:.5f}\".format(acc, auc, recall))\n","    acc, auc, recall, results_tree = tree_decider(train_X_norm, train_y, test_X_norm, test_y)\n","    print(\"tree model: acc is {:.5f}, auc is {:.5f} and recall is {:.5f}\".format(acc, auc, recall))\n","    \n","    train_X_re, train_y_re = resampling(train_X, train_y)\n","\n","    five_fold_data = cross_validation(train_X_re, train_y_re)\n","    models = train(five_fold_data, train_X)\n","    acc_score, auc_score, the_recall_score, results_tabnet = tabnet_test(models, test_X, test_y)\n","    print(\"accuracy score is {:.5f}, roc auc score is {:.5f} and recall score is {:.5f}\".format(acc_score, auc_score, the_recall_score))\n","\n","    return results_tabnet, results_linear, results_tree, test_y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qF1kwCxrupcX","executionInfo":{"status":"ok","timestamp":1638491956979,"user_tz":300,"elapsed":24883,"user":{"displayName":"胡明哲","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14614187422162607500"}},"outputId":"fb142822-cc99-4f6b-8469-5370576f1a07"},"source":["results_tabnet, results_linear, results_tree, test_y = full_train()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["linear model: acc is 0.97593, auc is 0.97321 and recall is 0.33333\n","tree model: acc is 0.97593, auc is 0.93517 and recall is 0.33333\n","Device used : cuda\n","epoch 0  | loss: 7.01152 | val_0_unsup_loss: 431.34476|  0:00:00s\n","epoch 1  | loss: 5.52149 | val_0_unsup_loss: 126.33997|  0:00:00s\n","epoch 2  | loss: 3.8534  | val_0_unsup_loss: 48.93094|  0:00:00s\n","epoch 3  | loss: 3.3239  | val_0_unsup_loss: 25.75055|  0:00:00s\n","epoch 4  | loss: 2.89857 | val_0_unsup_loss: 23.25002|  0:00:00s\n","epoch 5  | loss: 2.76928 | val_0_unsup_loss: 17.08224|  0:00:00s\n","epoch 6  | loss: 2.85343 | val_0_unsup_loss: 8.42017 |  0:00:00s\n","epoch 7  | loss: 2.41335 | val_0_unsup_loss: 4.22153 |  0:00:00s\n","epoch 8  | loss: 2.36818 | val_0_unsup_loss: 2.89264 |  0:00:00s\n","epoch 9  | loss: 2.18703 | val_0_unsup_loss: 2.54389 |  0:00:00s\n","epoch 10 | loss: 2.02314 | val_0_unsup_loss: 2.36979 |  0:00:00s\n","epoch 11 | loss: 1.94401 | val_0_unsup_loss: 2.16618 |  0:00:00s\n","epoch 12 | loss: 1.82779 | val_0_unsup_loss: 2.06929 |  0:00:00s\n","epoch 13 | loss: 1.86053 | val_0_unsup_loss: 2.013   |  0:00:00s\n","epoch 14 | loss: 1.72086 | val_0_unsup_loss: 1.80013 |  0:00:01s\n","epoch 15 | loss: 1.75432 | val_0_unsup_loss: 1.75632 |  0:00:01s\n","epoch 16 | loss: 1.61807 | val_0_unsup_loss: 1.85415 |  0:00:01s\n","epoch 17 | loss: 1.54194 | val_0_unsup_loss: 1.92489 |  0:00:01s\n","epoch 18 | loss: 1.51613 | val_0_unsup_loss: 1.92278 |  0:00:01s\n","epoch 19 | loss: 1.42551 | val_0_unsup_loss: 1.82752 |  0:00:01s\n","epoch 20 | loss: 1.39443 | val_0_unsup_loss: 1.63948 |  0:00:01s\n","epoch 21 | loss: 1.25827 | val_0_unsup_loss: 1.54322 |  0:00:01s\n","epoch 22 | loss: 1.2535  | val_0_unsup_loss: 1.46124 |  0:00:01s\n","epoch 23 | loss: 1.18316 | val_0_unsup_loss: 1.38844 |  0:00:01s\n","epoch 24 | loss: 1.18156 | val_0_unsup_loss: 1.36468 |  0:00:01s\n","epoch 25 | loss: 1.08865 | val_0_unsup_loss: 1.34606 |  0:00:01s\n","epoch 26 | loss: 1.2038  | val_0_unsup_loss: 1.34344 |  0:00:01s\n","epoch 27 | loss: 1.07297 | val_0_unsup_loss: 1.36705 |  0:00:01s\n","epoch 28 | loss: 1.13757 | val_0_unsup_loss: 1.44003 |  0:00:01s\n","epoch 29 | loss: 1.09488 | val_0_unsup_loss: 1.3916  |  0:00:01s\n","epoch 30 | loss: 1.08506 | val_0_unsup_loss: 1.3744  |  0:00:02s\n","epoch 31 | loss: 1.09508 | val_0_unsup_loss: 1.32753 |  0:00:02s\n","epoch 32 | loss: 1.00467 | val_0_unsup_loss: 1.25642 |  0:00:02s\n","epoch 33 | loss: 1.01395 | val_0_unsup_loss: 1.19601 |  0:00:02s\n","epoch 34 | loss: 0.99406 | val_0_unsup_loss: 1.1619  |  0:00:02s\n","epoch 35 | loss: 0.95154 | val_0_unsup_loss: 1.12462 |  0:00:02s\n","epoch 36 | loss: 0.97206 | val_0_unsup_loss: 1.0937  |  0:00:02s\n","epoch 37 | loss: 1.03045 | val_0_unsup_loss: 1.06508 |  0:00:02s\n","epoch 38 | loss: 0.96086 | val_0_unsup_loss: 1.0506  |  0:00:02s\n","epoch 39 | loss: 0.94969 | val_0_unsup_loss: 1.03877 |  0:00:02s\n","epoch 40 | loss: 0.96583 | val_0_unsup_loss: 1.02878 |  0:00:02s\n","epoch 41 | loss: 0.93467 | val_0_unsup_loss: 0.98182 |  0:00:02s\n","epoch 42 | loss: 0.90073 | val_0_unsup_loss: 0.97566 |  0:00:02s\n","epoch 43 | loss: 0.92841 | val_0_unsup_loss: 0.96151 |  0:00:02s\n","epoch 44 | loss: 0.8918  | val_0_unsup_loss: 0.90928 |  0:00:02s\n","epoch 45 | loss: 0.88093 | val_0_unsup_loss: 0.88924 |  0:00:03s\n","epoch 46 | loss: 0.90468 | val_0_unsup_loss: 0.87718 |  0:00:03s\n","epoch 47 | loss: 0.86353 | val_0_unsup_loss: 0.86571 |  0:00:03s\n","epoch 48 | loss: 0.88402 | val_0_unsup_loss: 0.85137 |  0:00:03s\n","epoch 49 | loss: 0.866   | val_0_unsup_loss: 0.84011 |  0:00:03s\n","epoch 50 | loss: 0.83648 | val_0_unsup_loss: 0.82879 |  0:00:03s\n","epoch 51 | loss: 0.84598 | val_0_unsup_loss: 0.83169 |  0:00:03s\n","epoch 52 | loss: 0.84522 | val_0_unsup_loss: 0.84323 |  0:00:03s\n","epoch 53 | loss: 0.88443 | val_0_unsup_loss: 0.84937 |  0:00:03s\n","epoch 54 | loss: 0.83228 | val_0_unsup_loss: 0.84797 |  0:00:03s\n","epoch 55 | loss: 0.86874 | val_0_unsup_loss: 0.83668 |  0:00:03s\n","epoch 56 | loss: 0.83738 | val_0_unsup_loss: 0.82889 |  0:00:03s\n","epoch 57 | loss: 0.85789 | val_0_unsup_loss: 0.82413 |  0:00:03s\n","epoch 58 | loss: 0.79975 | val_0_unsup_loss: 0.81858 |  0:00:03s\n","epoch 59 | loss: 0.78747 | val_0_unsup_loss: 0.82383 |  0:00:03s\n","epoch 60 | loss: 0.79549 | val_0_unsup_loss: 0.82098 |  0:00:03s\n","epoch 61 | loss: 0.82498 | val_0_unsup_loss: 0.82101 |  0:00:04s\n","epoch 62 | loss: 0.89639 | val_0_unsup_loss: 0.81882 |  0:00:04s\n","epoch 63 | loss: 0.78145 | val_0_unsup_loss: 0.80518 |  0:00:04s\n","epoch 64 | loss: 0.81573 | val_0_unsup_loss: 0.8067  |  0:00:04s\n","epoch 65 | loss: 0.85143 | val_0_unsup_loss: 0.80754 |  0:00:04s\n","epoch 66 | loss: 0.80308 | val_0_unsup_loss: 0.80288 |  0:00:04s\n","epoch 67 | loss: 0.77487 | val_0_unsup_loss: 0.79332 |  0:00:04s\n","epoch 68 | loss: 0.82925 | val_0_unsup_loss: 0.77834 |  0:00:04s\n","epoch 69 | loss: 0.85587 | val_0_unsup_loss: 0.77362 |  0:00:04s\n","epoch 70 | loss: 0.83982 | val_0_unsup_loss: 0.78063 |  0:00:04s\n","epoch 71 | loss: 0.80637 | val_0_unsup_loss: 0.78865 |  0:00:04s\n","epoch 72 | loss: 0.8108  | val_0_unsup_loss: 0.79177 |  0:00:04s\n","epoch 73 | loss: 0.8435  | val_0_unsup_loss: 0.78908 |  0:00:04s\n","epoch 74 | loss: 0.7679  | val_0_unsup_loss: 0.79313 |  0:00:04s\n","epoch 75 | loss: 0.77869 | val_0_unsup_loss: 0.7941  |  0:00:04s\n","epoch 76 | loss: 0.79293 | val_0_unsup_loss: 0.80145 |  0:00:04s\n","epoch 77 | loss: 0.71345 | val_0_unsup_loss: 0.80712 |  0:00:05s\n","epoch 78 | loss: 0.77628 | val_0_unsup_loss: 0.80643 |  0:00:05s\n","epoch 79 | loss: 0.76481 | val_0_unsup_loss: 0.79982 |  0:00:05s\n","\n","Early stopping occurred at epoch 79 with best_epoch = 69 and best_val_0_unsup_loss = 0.77362\n","Best weights from best epoch are automatically used!\n","Device used : cuda\n","Loading weights from unsupervised pretraining\n","epoch 0  | loss: 0.51444 | train_auc: 0.88106 | train_accuracy: 0.52174 | valid_auc: 0.85892 | valid_accuracy: 0.54589 |  0:00:00s\n","epoch 1  | loss: 0.31055 | train_auc: 0.90211 | train_accuracy: 0.55676 | valid_auc: 0.90784 | valid_accuracy: 0.57488 |  0:00:00s\n","epoch 2  | loss: 0.23506 | train_auc: 0.93648 | train_accuracy: 0.56159 | valid_auc: 0.91699 | valid_accuracy: 0.56039 |  0:00:00s\n","epoch 3  | loss: 0.17959 | train_auc: 0.88881 | train_accuracy: 0.55556 | valid_auc: 0.87965 | valid_accuracy: 0.56039 |  0:00:00s\n","epoch 4  | loss: 0.14891 | train_auc: 0.79823 | train_accuracy: 0.55918 | valid_auc: 0.77638 | valid_accuracy: 0.57005 |  0:00:00s\n","epoch 5  | loss: 0.12096 | train_auc: 0.76694 | train_accuracy: 0.56039 | valid_auc: 0.71083 | valid_accuracy: 0.57005 |  0:00:00s\n","epoch 6  | loss: 0.10003 | train_auc: 0.77688 | train_accuracy: 0.5628  | valid_auc: 0.7296  | valid_accuracy: 0.57488 |  0:00:00s\n","epoch 7  | loss: 0.08929 | train_auc: 0.75841 | train_accuracy: 0.57126 | valid_auc: 0.71438 | valid_accuracy: 0.57488 |  0:00:00s\n","epoch 8  | loss: 0.07376 | train_auc: 0.7748  | train_accuracy: 0.57971 | valid_auc: 0.72586 | valid_accuracy: 0.57488 |  0:00:00s\n","epoch 9  | loss: 0.06348 | train_auc: 0.78456 | train_accuracy: 0.58696 | valid_auc: 0.72838 | valid_accuracy: 0.57971 |  0:00:00s\n","epoch 10 | loss: 0.05347 | train_auc: 0.79305 | train_accuracy: 0.593   | valid_auc: 0.73511 | valid_accuracy: 0.58454 |  0:00:00s\n","epoch 11 | loss: 0.07273 | train_auc: 0.80591 | train_accuracy: 0.59903 | valid_auc: 0.75518 | valid_accuracy: 0.5942  |  0:00:00s\n","epoch 12 | loss: 0.0531  | train_auc: 0.81678 | train_accuracy: 0.60749 | valid_auc: 0.76172 | valid_accuracy: 0.5942  |  0:00:00s\n","epoch 13 | loss: 0.05367 | train_auc: 0.83938 | train_accuracy: 0.61473 | valid_auc: 0.78301 | valid_accuracy: 0.5942  |  0:00:00s\n","epoch 14 | loss: 0.03669 | train_auc: 0.8512  | train_accuracy: 0.62077 | valid_auc: 0.79935 | valid_accuracy: 0.5942  |  0:00:00s\n","epoch 15 | loss: 0.04704 | train_auc: 0.85177 | train_accuracy: 0.62681 | valid_auc: 0.79561 | valid_accuracy: 0.5942  |  0:00:01s\n","epoch 16 | loss: 0.04561 | train_auc: 0.87916 | train_accuracy: 0.6401  | valid_auc: 0.82283 | valid_accuracy: 0.6087  |  0:00:01s\n","epoch 17 | loss: 0.03701 | train_auc: 0.89466 | train_accuracy: 0.64976 | valid_auc: 0.84127 | valid_accuracy: 0.62802 |  0:00:01s\n","epoch 18 | loss: 0.03253 | train_auc: 0.89381 | train_accuracy: 0.65459 | valid_auc: 0.84351 | valid_accuracy: 0.63285 |  0:00:01s\n","epoch 19 | loss: 0.01737 | train_auc: 0.8941  | train_accuracy: 0.66304 | valid_auc: 0.843   | valid_accuracy: 0.63285 |  0:00:01s\n","epoch 20 | loss: 0.04047 | train_auc: 0.89804 | train_accuracy: 0.66667 | valid_auc: 0.84981 | valid_accuracy: 0.63768 |  0:00:01s\n","epoch 21 | loss: 0.02658 | train_auc: 0.89872 | train_accuracy: 0.67029 | valid_auc: 0.85882 | valid_accuracy: 0.64251 |  0:00:01s\n","epoch 22 | loss: 0.02053 | train_auc: 0.89578 | train_accuracy: 0.67391 | valid_auc: 0.85938 | valid_accuracy: 0.63768 |  0:00:01s\n","epoch 23 | loss: 0.02246 | train_auc: 0.89362 | train_accuracy: 0.67874 | valid_auc: 0.85859 | valid_accuracy: 0.64251 |  0:00:01s\n","epoch 24 | loss: 0.01379 | train_auc: 0.89725 | train_accuracy: 0.68116 | valid_auc: 0.85742 | valid_accuracy: 0.64734 |  0:00:01s\n","epoch 25 | loss: 0.01396 | train_auc: 0.90279 | train_accuracy: 0.68961 | valid_auc: 0.86368 | valid_accuracy: 0.65217 |  0:00:01s\n","epoch 26 | loss: 0.02133 | train_auc: 0.90302 | train_accuracy: 0.69928 | valid_auc: 0.87166 | valid_accuracy: 0.66667 |  0:00:01s\n","epoch 27 | loss: 0.01995 | train_auc: 0.90442 | train_accuracy: 0.70531 | valid_auc: 0.87731 | valid_accuracy: 0.68116 |  0:00:01s\n","epoch 28 | loss: 0.01569 | train_auc: 0.90484 | train_accuracy: 0.71618 | valid_auc: 0.87465 | valid_accuracy: 0.68116 |  0:00:01s\n","epoch 29 | loss: 0.02489 | train_auc: 0.90709 | train_accuracy: 0.71981 | valid_auc: 0.8704  | valid_accuracy: 0.69082 |  0:00:01s\n","epoch 30 | loss: 0.01306 | train_auc: 0.91209 | train_accuracy: 0.72222 | valid_auc: 0.87526 | valid_accuracy: 0.70048 |  0:00:02s\n","epoch 31 | loss: 0.01219 | train_auc: 0.91562 | train_accuracy: 0.72464 | valid_auc: 0.87792 | valid_accuracy: 0.70531 |  0:00:02s\n","epoch 32 | loss: 0.01968 | train_auc: 0.91475 | train_accuracy: 0.72947 | valid_auc: 0.88007 | valid_accuracy: 0.71498 |  0:00:02s\n","epoch 33 | loss: 0.017   | train_auc: 0.91319 | train_accuracy: 0.73068 | valid_auc: 0.87586 | valid_accuracy: 0.71498 |  0:00:02s\n","epoch 34 | loss: 0.01666 | train_auc: 0.91008 | train_accuracy: 0.7343  | valid_auc: 0.86611 | valid_accuracy: 0.71981 |  0:00:02s\n","epoch 35 | loss: 0.01179 | train_auc: 0.90669 | train_accuracy: 0.73792 | valid_auc: 0.8605  | valid_accuracy: 0.71498 |  0:00:02s\n","epoch 36 | loss: 0.01761 | train_auc: 0.90074 | train_accuracy: 0.74275 | valid_auc: 0.8564  | valid_accuracy: 0.72947 |  0:00:02s\n","epoch 37 | loss: 0.01094 | train_auc: 0.89676 | train_accuracy: 0.74758 | valid_auc: 0.85047 | valid_accuracy: 0.72464 |  0:00:02s\n","epoch 38 | loss: 0.01904 | train_auc: 0.89468 | train_accuracy: 0.75725 | valid_auc: 0.85327 | valid_accuracy: 0.72947 |  0:00:02s\n","epoch 39 | loss: 0.017   | train_auc: 0.89553 | train_accuracy: 0.76449 | valid_auc: 0.85537 | valid_accuracy: 0.74396 |  0:00:02s\n","epoch 40 | loss: 0.01439 | train_auc: 0.91756 | train_accuracy: 0.77657 | valid_auc: 0.88086 | valid_accuracy: 0.75845 |  0:00:02s\n","epoch 41 | loss: 0.01289 | train_auc: 0.93205 | train_accuracy: 0.77778 | valid_auc: 0.89594 | valid_accuracy: 0.76329 |  0:00:02s\n","epoch 42 | loss: 0.0103  | train_auc: 0.93821 | train_accuracy: 0.7814  | valid_auc: 0.90182 | valid_accuracy: 0.78261 |  0:00:02s\n","epoch 43 | loss: 0.01236 | train_auc: 0.94292 | train_accuracy: 0.78744 | valid_auc: 0.90878 | valid_accuracy: 0.78744 |  0:00:02s\n","epoch 44 | loss: 0.0135  | train_auc: 0.94798 | train_accuracy: 0.79227 | valid_auc: 0.91797 | valid_accuracy: 0.78744 |  0:00:02s\n","epoch 45 | loss: 0.00966 | train_auc: 0.95226 | train_accuracy: 0.79831 | valid_auc: 0.92544 | valid_accuracy: 0.79227 |  0:00:03s\n","epoch 46 | loss: 0.00604 | train_auc: 0.95519 | train_accuracy: 0.80435 | valid_auc: 0.92862 | valid_accuracy: 0.79227 |  0:00:03s\n","epoch 47 | loss: 0.00733 | train_auc: 0.95716 | train_accuracy: 0.8128  | valid_auc: 0.93147 | valid_accuracy: 0.79227 |  0:00:03s\n","epoch 48 | loss: 0.01105 | train_auc: 0.95828 | train_accuracy: 0.81522 | valid_auc: 0.9352  | valid_accuracy: 0.7971  |  0:00:03s\n","epoch 49 | loss: 0.00986 | train_auc: 0.95894 | train_accuracy: 0.81643 | valid_auc: 0.93613 | valid_accuracy: 0.80193 |  0:00:03s\n","epoch 50 | loss: 0.00533 | train_auc: 0.96049 | train_accuracy: 0.81884 | valid_auc: 0.93361 | valid_accuracy: 0.80193 |  0:00:03s\n","epoch 51 | loss: 0.00686 | train_auc: 0.96164 | train_accuracy: 0.82246 | valid_auc: 0.93394 | valid_accuracy: 0.80676 |  0:00:03s\n","epoch 52 | loss: 0.0124  | train_auc: 0.96045 | train_accuracy: 0.82609 | valid_auc: 0.93193 | valid_accuracy: 0.81643 |  0:00:03s\n","epoch 53 | loss: 0.01156 | train_auc: 0.95984 | train_accuracy: 0.8285  | valid_auc: 0.93175 | valid_accuracy: 0.81643 |  0:00:03s\n","epoch 54 | loss: 0.0044  | train_auc: 0.95974 | train_accuracy: 0.82971 | valid_auc: 0.93338 | valid_accuracy: 0.82126 |  0:00:03s\n","epoch 55 | loss: 0.00337 | train_auc: 0.95978 | train_accuracy: 0.82971 | valid_auc: 0.93329 | valid_accuracy: 0.82609 |  0:00:03s\n","epoch 56 | loss: 0.00533 | train_auc: 0.96007 | train_accuracy: 0.83092 | valid_auc: 0.93347 | valid_accuracy: 0.83575 |  0:00:03s\n","epoch 57 | loss: 0.00574 | train_auc: 0.95967 | train_accuracy: 0.83092 | valid_auc: 0.93119 | valid_accuracy: 0.84058 |  0:00:03s\n","epoch 58 | loss: 0.00305 | train_auc: 0.95761 | train_accuracy: 0.83213 | valid_auc: 0.92796 | valid_accuracy: 0.84058 |  0:00:03s\n","epoch 59 | loss: 0.00308 | train_auc: 0.95574 | train_accuracy: 0.83454 | valid_auc: 0.92414 | valid_accuracy: 0.83092 |  0:00:04s\n","epoch 60 | loss: 0.00352 | train_auc: 0.95155 | train_accuracy: 0.83454 | valid_auc: 0.919   | valid_accuracy: 0.83092 |  0:00:04s\n","epoch 61 | loss: 0.0033  | train_auc: 0.94743 | train_accuracy: 0.83575 | valid_auc: 0.91601 | valid_accuracy: 0.83092 |  0:00:04s\n","epoch 62 | loss: 0.0033  | train_auc: 0.9464  | train_accuracy: 0.83816 | valid_auc: 0.91765 | valid_accuracy: 0.83092 |  0:00:04s\n","epoch 63 | loss: 0.00601 | train_auc: 0.94479 | train_accuracy: 0.84058 | valid_auc: 0.91807 | valid_accuracy: 0.82126 |  0:00:04s\n","epoch 64 | loss: 0.00517 | train_auc: 0.94223 | train_accuracy: 0.8442  | valid_auc: 0.91816 | valid_accuracy: 0.82609 |  0:00:04s\n","epoch 65 | loss: 0.00503 | train_auc: 0.94356 | train_accuracy: 0.84783 | valid_auc: 0.91965 | valid_accuracy: 0.82609 |  0:00:04s\n","epoch 66 | loss: 0.00428 | train_auc: 0.94562 | train_accuracy: 0.84903 | valid_auc: 0.91844 | valid_accuracy: 0.82609 |  0:00:04s\n","epoch 67 | loss: 0.00424 | train_auc: 0.94804 | train_accuracy: 0.85145 | valid_auc: 0.91867 | valid_accuracy: 0.83575 |  0:00:04s\n","\n","Early stopping occurred at epoch 67 with best_epoch = 57 and best_valid_accuracy = 0.84058\n","Best weights from best epoch are automatically used!\n","Loading weights from unsupervised pretraining\n","epoch 0  | loss: 0.34296 | train_auc: 0.94612 | train_accuracy: 0.59058 | valid_auc: 0.9563  | valid_accuracy: 0.56522 |  0:00:00s\n","epoch 1  | loss: 0.20894 | train_auc: 0.82273 | train_accuracy: 0.56401 | valid_auc: 0.84305 | valid_accuracy: 0.53623 |  0:00:00s\n","epoch 2  | loss: 0.17081 | train_auc: 0.67364 | train_accuracy: 0.53019 | valid_auc: 0.7234  | valid_accuracy: 0.49758 |  0:00:00s\n","epoch 3  | loss: 0.13301 | train_auc: 0.645   | train_accuracy: 0.53744 | valid_auc: 0.70122 | valid_accuracy: 0.50725 |  0:00:00s\n","epoch 4  | loss: 0.1125  | train_auc: 0.66629 | train_accuracy: 0.5471  | valid_auc: 0.71466 | valid_accuracy: 0.51208 |  0:00:00s\n","epoch 5  | loss: 0.10003 | train_auc: 0.69528 | train_accuracy: 0.57488 | valid_auc: 0.74305 | valid_accuracy: 0.54589 |  0:00:00s\n","epoch 6  | loss: 0.08794 | train_auc: 0.70894 | train_accuracy: 0.58575 | valid_auc: 0.74586 | valid_accuracy: 0.55072 |  0:00:00s\n","epoch 7  | loss: 0.08213 | train_auc: 0.7012  | train_accuracy: 0.59179 | valid_auc: 0.7453  | valid_accuracy: 0.56039 |  0:00:00s\n","epoch 8  | loss: 0.06377 | train_auc: 0.72848 | train_accuracy: 0.59783 | valid_auc: 0.77086 | valid_accuracy: 0.56522 |  0:00:00s\n","epoch 9  | loss: 0.05655 | train_auc: 0.77545 | train_accuracy: 0.60024 | valid_auc: 0.8047  | valid_accuracy: 0.57488 |  0:00:00s\n","epoch 10 | loss: 0.05535 | train_auc: 0.80957 | train_accuracy: 0.6087  | valid_auc: 0.82773 | valid_accuracy: 0.57971 |  0:00:00s\n","epoch 11 | loss: 0.04753 | train_auc: 0.79952 | train_accuracy: 0.6087  | valid_auc: 0.80658 | valid_accuracy: 0.58454 |  0:00:00s\n","epoch 12 | loss: 0.03994 | train_auc: 0.81226 | train_accuracy: 0.61232 | valid_auc: 0.83233 | valid_accuracy: 0.58454 |  0:00:00s\n","epoch 13 | loss: 0.05368 | train_auc: 0.81788 | train_accuracy: 0.61836 | valid_auc: 0.83806 | valid_accuracy: 0.58454 |  0:00:00s\n","epoch 14 | loss: 0.02828 | train_auc: 0.81127 | train_accuracy: 0.62077 | valid_auc: 0.82791 | valid_accuracy: 0.59903 |  0:00:01s\n","epoch 15 | loss: 0.03304 | train_auc: 0.79523 | train_accuracy: 0.62198 | valid_auc: 0.83092 | valid_accuracy: 0.60386 |  0:00:01s\n","epoch 16 | loss: 0.02793 | train_auc: 0.77339 | train_accuracy: 0.62319 | valid_auc: 0.81259 | valid_accuracy: 0.60386 |  0:00:01s\n","epoch 17 | loss: 0.02614 | train_auc: 0.75361 | train_accuracy: 0.6256  | valid_auc: 0.79286 | valid_accuracy: 0.6087  |  0:00:01s\n","epoch 18 | loss: 0.02124 | train_auc: 0.73046 | train_accuracy: 0.63164 | valid_auc: 0.78581 | valid_accuracy: 0.61353 |  0:00:01s\n","epoch 19 | loss: 0.02049 | train_auc: 0.72464 | train_accuracy: 0.63527 | valid_auc: 0.78675 | valid_accuracy: 0.61836 |  0:00:01s\n","epoch 20 | loss: 0.02546 | train_auc: 0.73281 | train_accuracy: 0.64493 | valid_auc: 0.79718 | valid_accuracy: 0.62802 |  0:00:01s\n","epoch 21 | loss: 0.01884 | train_auc: 0.75042 | train_accuracy: 0.65338 | valid_auc: 0.80738 | valid_accuracy: 0.63285 |  0:00:01s\n","epoch 22 | loss: 0.01338 | train_auc: 0.76218 | train_accuracy: 0.65821 | valid_auc: 0.80879 | valid_accuracy: 0.64734 |  0:00:01s\n","epoch 23 | loss: 0.01263 | train_auc: 0.78062 | train_accuracy: 0.66667 | valid_auc: 0.82044 | valid_accuracy: 0.64734 |  0:00:01s\n","epoch 24 | loss: 0.01505 | train_auc: 0.833   | train_accuracy: 0.67271 | valid_auc: 0.86692 | valid_accuracy: 0.65217 |  0:00:01s\n","epoch 25 | loss: 0.01104 | train_auc: 0.83962 | train_accuracy: 0.67754 | valid_auc: 0.88224 | valid_accuracy: 0.657   |  0:00:01s\n","epoch 26 | loss: 0.01247 | train_auc: 0.85142 | train_accuracy: 0.68116 | valid_auc: 0.89173 | valid_accuracy: 0.67633 |  0:00:01s\n","epoch 27 | loss: 0.0174  | train_auc: 0.85528 | train_accuracy: 0.68237 | valid_auc: 0.89605 | valid_accuracy: 0.69082 |  0:00:01s\n","epoch 28 | loss: 0.01308 | train_auc: 0.85439 | train_accuracy: 0.6872  | valid_auc: 0.89887 | valid_accuracy: 0.70531 |  0:00:02s\n","epoch 29 | loss: 0.03592 | train_auc: 0.86332 | train_accuracy: 0.69203 | valid_auc: 0.89126 | valid_accuracy: 0.71014 |  0:00:02s\n","epoch 30 | loss: 0.01239 | train_auc: 0.87232 | train_accuracy: 0.69565 | valid_auc: 0.89182 | valid_accuracy: 0.71498 |  0:00:02s\n","epoch 31 | loss: 0.01548 | train_auc: 0.88265 | train_accuracy: 0.7029  | valid_auc: 0.89962 | valid_accuracy: 0.72464 |  0:00:02s\n","epoch 32 | loss: 0.0086  | train_auc: 0.88674 | train_accuracy: 0.7186  | valid_auc: 0.90695 | valid_accuracy: 0.73913 |  0:00:02s\n","epoch 33 | loss: 0.01    | train_auc: 0.89582 | train_accuracy: 0.72705 | valid_auc: 0.91386 | valid_accuracy: 0.74879 |  0:00:02s\n","epoch 34 | loss: 0.00825 | train_auc: 0.89908 | train_accuracy: 0.73309 | valid_auc: 0.91927 | valid_accuracy: 0.74879 |  0:00:02s\n","epoch 35 | loss: 0.01874 | train_auc: 0.90442 | train_accuracy: 0.73671 | valid_auc: 0.92213 | valid_accuracy: 0.75845 |  0:00:02s\n","epoch 36 | loss: 0.01198 | train_auc: 0.90956 | train_accuracy: 0.74396 | valid_auc: 0.92528 | valid_accuracy: 0.76812 |  0:00:02s\n","epoch 37 | loss: 0.0156  | train_auc: 0.91292 | train_accuracy: 0.75    | valid_auc: 0.92773 | valid_accuracy: 0.77295 |  0:00:02s\n","epoch 38 | loss: 0.00862 | train_auc: 0.91674 | train_accuracy: 0.75483 | valid_auc: 0.93144 | valid_accuracy: 0.77778 |  0:00:02s\n","epoch 39 | loss: 0.00814 | train_auc: 0.92085 | train_accuracy: 0.75966 | valid_auc: 0.93496 | valid_accuracy: 0.78261 |  0:00:02s\n","epoch 40 | loss: 0.01174 | train_auc: 0.93089 | train_accuracy: 0.76449 | valid_auc: 0.93849 | valid_accuracy: 0.78261 |  0:00:02s\n","epoch 41 | loss: 0.03021 | train_auc: 0.93316 | train_accuracy: 0.76691 | valid_auc: 0.94206 | valid_accuracy: 0.78744 |  0:00:02s\n","epoch 42 | loss: 0.00639 | train_auc: 0.93372 | train_accuracy: 0.77415 | valid_auc: 0.93694 | valid_accuracy: 0.79227 |  0:00:03s\n","epoch 43 | loss: 0.00795 | train_auc: 0.93464 | train_accuracy: 0.77657 | valid_auc: 0.93797 | valid_accuracy: 0.79227 |  0:00:03s\n","epoch 44 | loss: 0.01463 | train_auc: 0.93354 | train_accuracy: 0.78261 | valid_auc: 0.94032 | valid_accuracy: 0.80193 |  0:00:03s\n","epoch 45 | loss: 0.00991 | train_auc: 0.93307 | train_accuracy: 0.78623 | valid_auc: 0.94041 | valid_accuracy: 0.81159 |  0:00:03s\n","epoch 46 | loss: 0.01377 | train_auc: 0.93335 | train_accuracy: 0.78744 | valid_auc: 0.94192 | valid_accuracy: 0.81643 |  0:00:03s\n","epoch 47 | loss: 0.0039  | train_auc: 0.93554 | train_accuracy: 0.79589 | valid_auc: 0.94398 | valid_accuracy: 0.81643 |  0:00:03s\n","epoch 48 | loss: 0.00474 | train_auc: 0.93801 | train_accuracy: 0.79831 | valid_auc: 0.94803 | valid_accuracy: 0.82126 |  0:00:03s\n","epoch 49 | loss: 0.00853 | train_auc: 0.93883 | train_accuracy: 0.80314 | valid_auc: 0.94944 | valid_accuracy: 0.82126 |  0:00:03s\n","epoch 50 | loss: 0.00665 | train_auc: 0.94112 | train_accuracy: 0.80676 | valid_auc: 0.9532  | valid_accuracy: 0.82609 |  0:00:03s\n","epoch 51 | loss: 0.01107 | train_auc: 0.93955 | train_accuracy: 0.81159 | valid_auc: 0.95122 | valid_accuracy: 0.82609 |  0:00:03s\n","epoch 52 | loss: 0.00408 | train_auc: 0.93762 | train_accuracy: 0.81401 | valid_auc: 0.94915 | valid_accuracy: 0.82609 |  0:00:03s\n","epoch 53 | loss: 0.00767 | train_auc: 0.93695 | train_accuracy: 0.81643 | valid_auc: 0.94911 | valid_accuracy: 0.82609 |  0:00:03s\n","epoch 54 | loss: 0.00739 | train_auc: 0.93895 | train_accuracy: 0.82005 | valid_auc: 0.94685 | valid_accuracy: 0.82609 |  0:00:03s\n","epoch 55 | loss: 0.00466 | train_auc: 0.93831 | train_accuracy: 0.82246 | valid_auc: 0.94539 | valid_accuracy: 0.82126 |  0:00:03s\n","epoch 56 | loss: 0.00538 | train_auc: 0.93633 | train_accuracy: 0.82005 | valid_auc: 0.94037 | valid_accuracy: 0.82126 |  0:00:03s\n","epoch 57 | loss: 0.00458 | train_auc: 0.9352  | train_accuracy: 0.82488 | valid_auc: 0.93661 | valid_accuracy: 0.81643 |  0:00:03s\n","epoch 58 | loss: 0.00427 | train_auc: 0.93726 | train_accuracy: 0.82488 | valid_auc: 0.93872 | valid_accuracy: 0.81643 |  0:00:04s\n","epoch 59 | loss: 0.00534 | train_auc: 0.93743 | train_accuracy: 0.81884 | valid_auc: 0.93877 | valid_accuracy: 0.81643 |  0:00:04s\n","epoch 60 | loss: 0.00546 | train_auc: 0.93765 | train_accuracy: 0.82488 | valid_auc: 0.93576 | valid_accuracy: 0.82126 |  0:00:04s\n","\n","Early stopping occurred at epoch 60 with best_epoch = 50 and best_valid_accuracy = 0.82609\n","Best weights from best epoch are automatically used!\n","Loading weights from unsupervised pretraining\n","epoch 0  | loss: 0.32078 | train_auc: 0.87823 | train_accuracy: 0.58333 | valid_auc: 0.87974 | valid_accuracy: 0.57005 |  0:00:00s\n","epoch 1  | loss: 0.15523 | train_auc: 0.82847 | train_accuracy: 0.55918 | valid_auc: 0.77448 | valid_accuracy: 0.52657 |  0:00:00s\n","epoch 2  | loss: 0.12879 | train_auc: 0.62422 | train_accuracy: 0.55193 | valid_auc: 0.57885 | valid_accuracy: 0.50725 |  0:00:00s\n","epoch 3  | loss: 0.12295 | train_auc: 0.62164 | train_accuracy: 0.55072 | valid_auc: 0.59762 | valid_accuracy: 0.52174 |  0:00:00s\n","epoch 4  | loss: 0.1024  | train_auc: 0.6505  | train_accuracy: 0.56763 | valid_auc: 0.63214 | valid_accuracy: 0.5314  |  0:00:00s\n","epoch 5  | loss: 0.09123 | train_auc: 0.69505 | train_accuracy: 0.57609 | valid_auc: 0.676   | valid_accuracy: 0.55556 |  0:00:00s\n","epoch 6  | loss: 0.08018 | train_auc: 0.73888 | train_accuracy: 0.58213 | valid_auc: 0.706   | valid_accuracy: 0.57971 |  0:00:00s\n","epoch 7  | loss: 0.07786 | train_auc: 0.81832 | train_accuracy: 0.58816 | valid_auc: 0.77382 | valid_accuracy: 0.57971 |  0:00:00s\n","epoch 8  | loss: 0.06662 | train_auc: 0.85265 | train_accuracy: 0.60024 | valid_auc: 0.82602 | valid_accuracy: 0.58454 |  0:00:00s\n","epoch 9  | loss: 0.06252 | train_auc: 0.88705 | train_accuracy: 0.60266 | valid_auc: 0.88115 | valid_accuracy: 0.58454 |  0:00:00s\n","epoch 10 | loss: 0.06054 | train_auc: 0.8871  | train_accuracy: 0.60628 | valid_auc: 0.90728 | valid_accuracy: 0.58937 |  0:00:00s\n","epoch 11 | loss: 0.05096 | train_auc: 0.90366 | train_accuracy: 0.60749 | valid_auc: 0.90931 | valid_accuracy: 0.58937 |  0:00:00s\n","epoch 12 | loss: 0.04695 | train_auc: 0.91487 | train_accuracy: 0.61353 | valid_auc: 0.92803 | valid_accuracy: 0.59903 |  0:00:00s\n","epoch 13 | loss: 0.03806 | train_auc: 0.92119 | train_accuracy: 0.61836 | valid_auc: 0.92709 | valid_accuracy: 0.6087  |  0:00:00s\n","epoch 14 | loss: 0.03496 | train_auc: 0.92185 | train_accuracy: 0.62198 | valid_auc: 0.92563 | valid_accuracy: 0.61353 |  0:00:00s\n","epoch 15 | loss: 0.03916 | train_auc: 0.92007 | train_accuracy: 0.62923 | valid_auc: 0.91582 | valid_accuracy: 0.61836 |  0:00:01s\n","epoch 16 | loss: 0.03526 | train_auc: 0.91905 | train_accuracy: 0.63768 | valid_auc: 0.91124 | valid_accuracy: 0.61836 |  0:00:01s\n","epoch 17 | loss: 0.03267 | train_auc: 0.9137  | train_accuracy: 0.64734 | valid_auc: 0.89464 | valid_accuracy: 0.62802 |  0:00:01s\n","epoch 18 | loss: 0.0183  | train_auc: 0.90676 | train_accuracy: 0.65097 | valid_auc: 0.88252 | valid_accuracy: 0.63285 |  0:00:01s\n","epoch 19 | loss: 0.02607 | train_auc: 0.9061  | train_accuracy: 0.65459 | valid_auc: 0.87653 | valid_accuracy: 0.63768 |  0:00:01s\n","epoch 20 | loss: 0.0265  | train_auc: 0.91051 | train_accuracy: 0.66304 | valid_auc: 0.88983 | valid_accuracy: 0.65217 |  0:00:01s\n","epoch 21 | loss: 0.02464 | train_auc: 0.92682 | train_accuracy: 0.67633 | valid_auc: 0.92898 | valid_accuracy: 0.657   |  0:00:01s\n","epoch 22 | loss: 0.0342  | train_auc: 0.94034 | train_accuracy: 0.67995 | valid_auc: 0.93874 | valid_accuracy: 0.66184 |  0:00:01s\n","epoch 23 | loss: 0.01557 | train_auc: 0.94334 | train_accuracy: 0.67995 | valid_auc: 0.95246 | valid_accuracy: 0.66184 |  0:00:01s\n","epoch 24 | loss: 0.01401 | train_auc: 0.93856 | train_accuracy: 0.68237 | valid_auc: 0.94223 | valid_accuracy: 0.66667 |  0:00:01s\n","epoch 25 | loss: 0.01673 | train_auc: 0.92801 | train_accuracy: 0.68478 | valid_auc: 0.93015 | valid_accuracy: 0.66667 |  0:00:01s\n","epoch 26 | loss: 0.01932 | train_auc: 0.92182 | train_accuracy: 0.68841 | valid_auc: 0.92907 | valid_accuracy: 0.6715  |  0:00:01s\n","epoch 27 | loss: 0.01698 | train_auc: 0.92196 | train_accuracy: 0.69324 | valid_auc: 0.9302  | valid_accuracy: 0.6715  |  0:00:01s\n","epoch 28 | loss: 0.01535 | train_auc: 0.9239  | train_accuracy: 0.70411 | valid_auc: 0.92204 | valid_accuracy: 0.6715  |  0:00:02s\n","epoch 29 | loss: 0.01298 | train_auc: 0.9369  | train_accuracy: 0.71014 | valid_auc: 0.93412 | valid_accuracy: 0.67633 |  0:00:02s\n","epoch 30 | loss: 0.01606 | train_auc: 0.93835 | train_accuracy: 0.72101 | valid_auc: 0.93327 | valid_accuracy: 0.68116 |  0:00:02s\n","epoch 31 | loss: 0.01924 | train_auc: 0.93721 | train_accuracy: 0.72705 | valid_auc: 0.91983 | valid_accuracy: 0.69565 |  0:00:02s\n","epoch 32 | loss: 0.01431 | train_auc: 0.93566 | train_accuracy: 0.73551 | valid_auc: 0.91261 | valid_accuracy: 0.69565 |  0:00:02s\n","epoch 33 | loss: 0.0162  | train_auc: 0.9395  | train_accuracy: 0.74638 | valid_auc: 0.92992 | valid_accuracy: 0.69565 |  0:00:02s\n","epoch 34 | loss: 0.00679 | train_auc: 0.94395 | train_accuracy: 0.74758 | valid_auc: 0.93379 | valid_accuracy: 0.70531 |  0:00:02s\n","epoch 35 | loss: 0.01554 | train_auc: 0.94907 | train_accuracy: 0.75242 | valid_auc: 0.94232 | valid_accuracy: 0.70531 |  0:00:02s\n","epoch 36 | loss: 0.01687 | train_auc: 0.95543 | train_accuracy: 0.75604 | valid_auc: 0.94935 | valid_accuracy: 0.71498 |  0:00:02s\n","epoch 37 | loss: 0.01433 | train_auc: 0.95327 | train_accuracy: 0.76449 | valid_auc: 0.94194 | valid_accuracy: 0.72464 |  0:00:02s\n","epoch 38 | loss: 0.02022 | train_auc: 0.94778 | train_accuracy: 0.77053 | valid_auc: 0.94925 | valid_accuracy: 0.72947 |  0:00:02s\n","epoch 39 | loss: 0.01034 | train_auc: 0.95155 | train_accuracy: 0.77657 | valid_auc: 0.94161 | valid_accuracy: 0.72947 |  0:00:02s\n","epoch 40 | loss: 0.01203 | train_auc: 0.95298 | train_accuracy: 0.78019 | valid_auc: 0.94826 | valid_accuracy: 0.73913 |  0:00:02s\n","epoch 41 | loss: 0.01184 | train_auc: 0.94904 | train_accuracy: 0.7814  | valid_auc: 0.95274 | valid_accuracy: 0.73913 |  0:00:02s\n","epoch 42 | loss: 0.00657 | train_auc: 0.9545  | train_accuracy: 0.78744 | valid_auc: 0.95053 | valid_accuracy: 0.75362 |  0:00:02s\n","epoch 43 | loss: 0.01231 | train_auc: 0.95715 | train_accuracy: 0.78986 | valid_auc: 0.94355 | valid_accuracy: 0.75362 |  0:00:03s\n","epoch 44 | loss: 0.01276 | train_auc: 0.95869 | train_accuracy: 0.79831 | valid_auc: 0.95166 | valid_accuracy: 0.75845 |  0:00:03s\n","epoch 45 | loss: 0.01329 | train_auc: 0.95816 | train_accuracy: 0.80435 | valid_auc: 0.94746 | valid_accuracy: 0.75845 |  0:00:03s\n","epoch 46 | loss: 0.00601 | train_auc: 0.95722 | train_accuracy: 0.81159 | valid_auc: 0.94897 | valid_accuracy: 0.76329 |  0:00:03s\n","epoch 47 | loss: 0.01074 | train_auc: 0.9527  | train_accuracy: 0.81401 | valid_auc: 0.94779 | valid_accuracy: 0.77295 |  0:00:03s\n","epoch 48 | loss: 0.00758 | train_auc: 0.94765 | train_accuracy: 0.81401 | valid_auc: 0.941   | valid_accuracy: 0.77778 |  0:00:03s\n","epoch 49 | loss: 0.00665 | train_auc: 0.94769 | train_accuracy: 0.81763 | valid_auc: 0.93765 | valid_accuracy: 0.77778 |  0:00:03s\n","epoch 50 | loss: 0.01313 | train_auc: 0.94536 | train_accuracy: 0.81884 | valid_auc: 0.93912 | valid_accuracy: 0.77778 |  0:00:03s\n","epoch 51 | loss: 0.00651 | train_auc: 0.94282 | train_accuracy: 0.82126 | valid_auc: 0.93982 | valid_accuracy: 0.77778 |  0:00:03s\n","epoch 52 | loss: 0.00494 | train_auc: 0.94215 | train_accuracy: 0.82246 | valid_auc: 0.94124 | valid_accuracy: 0.77778 |  0:00:03s\n","epoch 53 | loss: 0.00615 | train_auc: 0.94397 | train_accuracy: 0.82488 | valid_auc: 0.94119 | valid_accuracy: 0.78261 |  0:00:03s\n","epoch 54 | loss: 0.01121 | train_auc: 0.94591 | train_accuracy: 0.82609 | valid_auc: 0.93949 | valid_accuracy: 0.7971  |  0:00:03s\n","epoch 55 | loss: 0.00545 | train_auc: 0.94723 | train_accuracy: 0.82971 | valid_auc: 0.94114 | valid_accuracy: 0.80193 |  0:00:03s\n","epoch 56 | loss: 0.00514 | train_auc: 0.94684 | train_accuracy: 0.83092 | valid_auc: 0.94468 | valid_accuracy: 0.81159 |  0:00:03s\n","epoch 57 | loss: 0.00445 | train_auc: 0.9462  | train_accuracy: 0.83575 | valid_auc: 0.94803 | valid_accuracy: 0.81643 |  0:00:03s\n","epoch 58 | loss: 0.00998 | train_auc: 0.94767 | train_accuracy: 0.83816 | valid_auc: 0.95407 | valid_accuracy: 0.82609 |  0:00:04s\n","epoch 59 | loss: 0.01411 | train_auc: 0.94811 | train_accuracy: 0.8442  | valid_auc: 0.95421 | valid_accuracy: 0.82609 |  0:00:04s\n","epoch 60 | loss: 0.00756 | train_auc: 0.94719 | train_accuracy: 0.84662 | valid_auc: 0.95746 | valid_accuracy: 0.82609 |  0:00:04s\n","epoch 61 | loss: 0.00576 | train_auc: 0.94241 | train_accuracy: 0.84783 | valid_auc: 0.95534 | valid_accuracy: 0.82609 |  0:00:04s\n","epoch 62 | loss: 0.00591 | train_auc: 0.94102 | train_accuracy: 0.85386 | valid_auc: 0.9618  | valid_accuracy: 0.82609 |  0:00:04s\n","epoch 63 | loss: 0.00891 | train_auc: 0.94088 | train_accuracy: 0.85507 | valid_auc: 0.96171 | valid_accuracy: 0.83092 |  0:00:04s\n","epoch 64 | loss: 0.00477 | train_auc: 0.94104 | train_accuracy: 0.8599  | valid_auc: 0.9601  | valid_accuracy: 0.83092 |  0:00:04s\n","epoch 65 | loss: 0.00443 | train_auc: 0.94684 | train_accuracy: 0.86111 | valid_auc: 0.96741 | valid_accuracy: 0.83575 |  0:00:04s\n","epoch 66 | loss: 0.01135 | train_auc: 0.94777 | train_accuracy: 0.86836 | valid_auc: 0.96902 | valid_accuracy: 0.83092 |  0:00:04s\n","epoch 67 | loss: 0.01029 | train_auc: 0.9495  | train_accuracy: 0.87319 | valid_auc: 0.9701  | valid_accuracy: 0.83092 |  0:00:04s\n","epoch 68 | loss: 0.00706 | train_auc: 0.95228 | train_accuracy: 0.8756  | valid_auc: 0.97194 | valid_accuracy: 0.83092 |  0:00:04s\n","epoch 69 | loss: 0.01506 | train_auc: 0.95505 | train_accuracy: 0.87802 | valid_auc: 0.97029 | valid_accuracy: 0.83575 |  0:00:04s\n","epoch 70 | loss: 0.00553 | train_auc: 0.9554  | train_accuracy: 0.88285 | valid_auc: 0.96902 | valid_accuracy: 0.83575 |  0:00:04s\n","epoch 71 | loss: 0.00805 | train_auc: 0.95528 | train_accuracy: 0.88647 | valid_auc: 0.96953 | valid_accuracy: 0.84058 |  0:00:04s\n","epoch 72 | loss: 0.00515 | train_auc: 0.95481 | train_accuracy: 0.88647 | valid_auc: 0.96996 | valid_accuracy: 0.84058 |  0:00:04s\n","epoch 73 | loss: 0.00465 | train_auc: 0.95676 | train_accuracy: 0.88768 | valid_auc: 0.9701  | valid_accuracy: 0.84058 |  0:00:05s\n","epoch 74 | loss: 0.00498 | train_auc: 0.95732 | train_accuracy: 0.88768 | valid_auc: 0.96982 | valid_accuracy: 0.84541 |  0:00:05s\n","epoch 75 | loss: 0.00324 | train_auc: 0.95703 | train_accuracy: 0.88406 | valid_auc: 0.9709  | valid_accuracy: 0.83575 |  0:00:05s\n","epoch 76 | loss: 0.00324 | train_auc: 0.95824 | train_accuracy: 0.88406 | valid_auc: 0.97095 | valid_accuracy: 0.84058 |  0:00:05s\n","epoch 77 | loss: 0.00603 | train_auc: 0.95833 | train_accuracy: 0.88647 | valid_auc: 0.97199 | valid_accuracy: 0.84058 |  0:00:05s\n","epoch 78 | loss: 0.00381 | train_auc: 0.95984 | train_accuracy: 0.88768 | valid_auc: 0.97175 | valid_accuracy: 0.84058 |  0:00:05s\n","epoch 79 | loss: 0.0058  | train_auc: 0.95943 | train_accuracy: 0.88768 | valid_auc: 0.97218 | valid_accuracy: 0.85024 |  0:00:05s\n","epoch 80 | loss: 0.00668 | train_auc: 0.96153 | train_accuracy: 0.89493 | valid_auc: 0.97194 | valid_accuracy: 0.86473 |  0:00:05s\n","epoch 81 | loss: 0.00717 | train_auc: 0.96245 | train_accuracy: 0.89614 | valid_auc: 0.96817 | valid_accuracy: 0.8744  |  0:00:05s\n","epoch 82 | loss: 0.00872 | train_auc: 0.96275 | train_accuracy: 0.89855 | valid_auc: 0.96736 | valid_accuracy: 0.8744  |  0:00:05s\n","epoch 83 | loss: 0.00647 | train_auc: 0.96244 | train_accuracy: 0.90217 | valid_auc: 0.9693  | valid_accuracy: 0.87923 |  0:00:05s\n","epoch 84 | loss: 0.00434 | train_auc: 0.96279 | train_accuracy: 0.90217 | valid_auc: 0.96916 | valid_accuracy: 0.87923 |  0:00:05s\n","epoch 85 | loss: 0.00353 | train_auc: 0.96364 | train_accuracy: 0.9058  | valid_auc: 0.96916 | valid_accuracy: 0.88406 |  0:00:05s\n","epoch 86 | loss: 0.00298 | train_auc: 0.96435 | train_accuracy: 0.907   | valid_auc: 0.97005 | valid_accuracy: 0.88406 |  0:00:05s\n","epoch 87 | loss: 0.00412 | train_auc: 0.9644  | train_accuracy: 0.907   | valid_auc: 0.97081 | valid_accuracy: 0.88406 |  0:00:06s\n","epoch 88 | loss: 0.00981 | train_auc: 0.96585 | train_accuracy: 0.91425 | valid_auc: 0.97076 | valid_accuracy: 0.88406 |  0:00:06s\n","epoch 89 | loss: 0.00298 | train_auc: 0.9669  | train_accuracy: 0.91787 | valid_auc: 0.97236 | valid_accuracy: 0.88889 |  0:00:06s\n","epoch 90 | loss: 0.00446 | train_auc: 0.96814 | train_accuracy: 0.92029 | valid_auc: 0.97345 | valid_accuracy: 0.88889 |  0:00:06s\n","epoch 91 | loss: 0.00259 | train_auc: 0.96884 | train_accuracy: 0.92271 | valid_auc: 0.9743  | valid_accuracy: 0.88889 |  0:00:06s\n","epoch 92 | loss: 0.00526 | train_auc: 0.96943 | train_accuracy: 0.92271 | valid_auc: 0.97533 | valid_accuracy: 0.88889 |  0:00:06s\n","epoch 93 | loss: 0.00974 | train_auc: 0.96991 | train_accuracy: 0.92271 | valid_auc: 0.97637 | valid_accuracy: 0.88889 |  0:00:06s\n","epoch 94 | loss: 0.00231 | train_auc: 0.97014 | train_accuracy: 0.92271 | valid_auc: 0.97684 | valid_accuracy: 0.90821 |  0:00:06s\n","epoch 95 | loss: 0.0035  | train_auc: 0.97137 | train_accuracy: 0.92391 | valid_auc: 0.97699 | valid_accuracy: 0.91304 |  0:00:06s\n","epoch 96 | loss: 0.00717 | train_auc: 0.97259 | train_accuracy: 0.92391 | valid_auc: 0.97722 | valid_accuracy: 0.91787 |  0:00:06s\n","epoch 97 | loss: 0.00439 | train_auc: 0.97383 | train_accuracy: 0.92391 | valid_auc: 0.97684 | valid_accuracy: 0.91787 |  0:00:06s\n","epoch 98 | loss: 0.0062  | train_auc: 0.97497 | train_accuracy: 0.92512 | valid_auc: 0.97708 | valid_accuracy: 0.91787 |  0:00:06s\n","epoch 99 | loss: 0.00853 | train_auc: 0.97545 | train_accuracy: 0.92633 | valid_auc: 0.97741 | valid_accuracy: 0.91787 |  0:00:06s\n","Stop training because you reached max_epochs = 100 with best_epoch = 96 and best_valid_accuracy = 0.91787\n","Best weights from best epoch are automatically used!\n","Loading weights from unsupervised pretraining\n","epoch 0  | loss: 0.3266  | train_auc: 0.97753 | train_accuracy: 0.59662 | valid_auc: 0.95822 | valid_accuracy: 0.61836 |  0:00:00s\n","epoch 1  | loss: 0.15503 | train_auc: 0.48496 | train_accuracy: 0.49396 | valid_auc: 0.50009 | valid_accuracy: 0.51691 |  0:00:00s\n","epoch 2  | loss: 0.13984 | train_auc: 0.54561 | train_accuracy: 0.50362 | valid_auc: 0.55807 | valid_accuracy: 0.51691 |  0:00:00s\n","epoch 3  | loss: 0.11866 | train_auc: 0.6344  | train_accuracy: 0.58092 | valid_auc: 0.67109 | valid_accuracy: 0.6087  |  0:00:00s\n","epoch 4  | loss: 0.08738 | train_auc: 0.73721 | train_accuracy: 0.59179 | valid_auc: 0.77795 | valid_accuracy: 0.63285 |  0:00:00s\n","epoch 5  | loss: 0.09124 | train_auc: 0.78942 | train_accuracy: 0.59541 | valid_auc: 0.83554 | valid_accuracy: 0.64251 |  0:00:00s\n","epoch 6  | loss: 0.07651 | train_auc: 0.81471 | train_accuracy: 0.5942  | valid_auc: 0.85572 | valid_accuracy: 0.63768 |  0:00:00s\n","epoch 7  | loss: 0.06529 | train_auc: 0.82968 | train_accuracy: 0.5942  | valid_auc: 0.86434 | valid_accuracy: 0.63285 |  0:00:00s\n","epoch 8  | loss: 0.05902 | train_auc: 0.84285 | train_accuracy: 0.593   | valid_auc: 0.87022 | valid_accuracy: 0.63285 |  0:00:00s\n","epoch 9  | loss: 0.05391 | train_auc: 0.87127 | train_accuracy: 0.59179 | valid_auc: 0.89532 | valid_accuracy: 0.62802 |  0:00:00s\n","epoch 10 | loss: 0.04727 | train_auc: 0.89981 | train_accuracy: 0.593   | valid_auc: 0.92777 | valid_accuracy: 0.62802 |  0:00:00s\n","epoch 11 | loss: 0.04366 | train_auc: 0.9097  | train_accuracy: 0.59541 | valid_auc: 0.93047 | valid_accuracy: 0.62802 |  0:00:00s\n","epoch 12 | loss: 0.03517 | train_auc: 0.929   | train_accuracy: 0.60386 | valid_auc: 0.94449 | valid_accuracy: 0.64251 |  0:00:00s\n","epoch 13 | loss: 0.04042 | train_auc: 0.93641 | train_accuracy: 0.6087  | valid_auc: 0.96239 | valid_accuracy: 0.65217 |  0:00:00s\n","epoch 14 | loss: 0.03948 | train_auc: 0.94392 | train_accuracy: 0.61594 | valid_auc: 0.97518 | valid_accuracy: 0.66184 |  0:00:01s\n","epoch 15 | loss: 0.02517 | train_auc: 0.94972 | train_accuracy: 0.61957 | valid_auc: 0.98191 | valid_accuracy: 0.6715  |  0:00:01s\n","epoch 16 | loss: 0.03307 | train_auc: 0.9572  | train_accuracy: 0.62802 | valid_auc: 0.98664 | valid_accuracy: 0.68599 |  0:00:01s\n","epoch 17 | loss: 0.03325 | train_auc: 0.95839 | train_accuracy: 0.63647 | valid_auc: 0.98745 | valid_accuracy: 0.68599 |  0:00:01s\n","epoch 18 | loss: 0.02052 | train_auc: 0.92993 | train_accuracy: 0.63164 | valid_auc: 0.92905 | valid_accuracy: 0.66184 |  0:00:01s\n","epoch 19 | loss: 0.02972 | train_auc: 0.89993 | train_accuracy: 0.62198 | valid_auc: 0.90423 | valid_accuracy: 0.65217 |  0:00:01s\n","epoch 20 | loss: 0.02235 | train_auc: 0.88853 | train_accuracy: 0.61836 | valid_auc: 0.91057 | valid_accuracy: 0.6715  |  0:00:01s\n","epoch 21 | loss: 0.02006 | train_auc: 0.893   | train_accuracy: 0.6256  | valid_auc: 0.93705 | valid_accuracy: 0.71498 |  0:00:01s\n","epoch 22 | loss: 0.02052 | train_auc: 0.87531 | train_accuracy: 0.64855 | valid_auc: 0.93288 | valid_accuracy: 0.74396 |  0:00:01s\n","epoch 23 | loss: 0.02493 | train_auc: 0.8716  | train_accuracy: 0.64976 | valid_auc: 0.93004 | valid_accuracy: 0.75845 |  0:00:01s\n","epoch 24 | loss: 0.01804 | train_auc: 0.87205 | train_accuracy: 0.64734 | valid_auc: 0.92848 | valid_accuracy: 0.7343  |  0:00:01s\n","epoch 25 | loss: 0.01456 | train_auc: 0.87244 | train_accuracy: 0.65338 | valid_auc: 0.929   | valid_accuracy: 0.7343  |  0:00:01s\n","epoch 26 | loss: 0.01603 | train_auc: 0.87282 | train_accuracy: 0.66184 | valid_auc: 0.93122 | valid_accuracy: 0.7343  |  0:00:01s\n","epoch 27 | loss: 0.01438 | train_auc: 0.87403 | train_accuracy: 0.66787 | valid_auc: 0.93416 | valid_accuracy: 0.73913 |  0:00:01s\n","epoch 28 | loss: 0.0157  | train_auc: 0.87842 | train_accuracy: 0.67754 | valid_auc: 0.93336 | valid_accuracy: 0.75362 |  0:00:01s\n","epoch 29 | loss: 0.02337 | train_auc: 0.87995 | train_accuracy: 0.68478 | valid_auc: 0.92909 | valid_accuracy: 0.74879 |  0:00:02s\n","epoch 30 | loss: 0.01319 | train_auc: 0.88109 | train_accuracy: 0.69565 | valid_auc: 0.92549 | valid_accuracy: 0.74879 |  0:00:02s\n","epoch 31 | loss: 0.01101 | train_auc: 0.88268 | train_accuracy: 0.70411 | valid_auc: 0.92203 | valid_accuracy: 0.74879 |  0:00:02s\n","epoch 32 | loss: 0.00971 | train_auc: 0.87742 | train_accuracy: 0.69324 | valid_auc: 0.92    | valid_accuracy: 0.74396 |  0:00:02s\n","epoch 33 | loss: 0.0146  | train_auc: 0.87615 | train_accuracy: 0.69807 | valid_auc: 0.92071 | valid_accuracy: 0.75845 |  0:00:02s\n","\n","Early stopping occurred at epoch 33 with best_epoch = 23 and best_valid_accuracy = 0.75845\n","Best weights from best epoch are automatically used!\n","Loading weights from unsupervised pretraining\n","epoch 0  | loss: 0.27689 | train_auc: 0.98829 | train_accuracy: 0.59058 | valid_auc: 0.9611  | valid_accuracy: 0.61353 |  0:00:00s\n","epoch 1  | loss: 0.12841 | train_auc: 0.97719 | train_accuracy: 0.56522 | valid_auc: 0.95371 | valid_accuracy: 0.58937 |  0:00:00s\n","epoch 2  | loss: 0.11864 | train_auc: 0.91625 | train_accuracy: 0.56039 | valid_auc: 0.92155 | valid_accuracy: 0.58937 |  0:00:00s\n","epoch 3  | loss: 0.0945  | train_auc: 0.87714 | train_accuracy: 0.55918 | valid_auc: 0.88504 | valid_accuracy: 0.58937 |  0:00:00s\n","epoch 4  | loss: 0.07543 | train_auc: 0.84494 | train_accuracy: 0.56401 | valid_auc: 0.84193 | valid_accuracy: 0.58454 |  0:00:00s\n","epoch 5  | loss: 0.05901 | train_auc: 0.80967 | train_accuracy: 0.56763 | valid_auc: 0.8196  | valid_accuracy: 0.58454 |  0:00:00s\n","epoch 6  | loss: 0.05102 | train_auc: 0.7675  | train_accuracy: 0.57488 | valid_auc: 0.78356 | valid_accuracy: 0.5942  |  0:00:00s\n","epoch 7  | loss: 0.04798 | train_auc: 0.7208  | train_accuracy: 0.58333 | valid_auc: 0.74115 | valid_accuracy: 0.5942  |  0:00:00s\n","epoch 8  | loss: 0.04082 | train_auc: 0.68886 | train_accuracy: 0.58696 | valid_auc: 0.69655 | valid_accuracy: 0.60386 |  0:00:00s\n","epoch 9  | loss: 0.03726 | train_auc: 0.64508 | train_accuracy: 0.58816 | valid_auc: 0.63471 | valid_accuracy: 0.6087  |  0:00:00s\n","epoch 10 | loss: 0.03264 | train_auc: 0.61472 | train_accuracy: 0.5942  | valid_auc: 0.60335 | valid_accuracy: 0.6087  |  0:00:00s\n","\n","Early stopping occurred at epoch 10 with best_epoch = 0 and best_valid_accuracy = 0.61353\n","Best weights from best epoch are automatically used!\n","accuracy score is 0.53148, roc auc score is 0.88190 and recall score is 0.93333\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C0EePj6K8Ti1","executionInfo":{"status":"ok","timestamp":1638492283213,"user_tz":300,"elapsed":4,"user":{"displayName":"胡明哲","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14614187422162607500"}},"outputId":"de7917aa-91ed-41da-d44b-1aab60ea68f2"},"source":["final_acc, final_recall = ensemble(results_tabnet, results_linear, results_tree, test_y)\n","print(\"final accuracy score is {:.5f}, recall score is {:.5f}\".format(final_acc, final_recall))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["final accuracy score is 0.82778, recall score is 0.80000\n"]}]},{"cell_type":"code","metadata":{"id":"_HcuUsk5D4zs"},"source":[""],"execution_count":null,"outputs":[]}]}